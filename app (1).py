"""
RAG TabanlÄ± CV Chatbot - Gemini Versiyonu
Nil YaÄŸmur Muslu'nun CV bilgilerini kullanarak sorulara cevap verir.
"""

# ===============================
# BÃ–LÃœM 1: Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi
# ===============================
import os
import pickle
import warnings
warnings.filterwarnings("ignore")

import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
try:
    from langchain_community.embeddings import HuggingFaceEmbeddings
except ImportError:
    from langchain.embeddings import HuggingFaceEmbeddings

# Google Gemini iÃ§in
from langchain_google_genai import ChatGoogleGenerativeAI

# ===============================
# BÃ–LÃœM 2: Streamlit Sayfa KonfigÃ¼rasyonu
# ===============================
st.set_page_config(
    page_title="Nil YaÄŸmur Muslu - CV Chatbot",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===============================
# BÃ–LÃœM 3: Sabit DeÄŸiÅŸkenler
# ===============================
DATA_FILE = "data.txt"
FAISS_INDEX_PATH = "./faiss_index.pkl"
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# Gemini API anahtarÄ±nÄ± Hugging Face "Secrets" kÄ±smÄ±ndan alacaÄŸÄ±z
# Hugging Face Ã¼zerinde: Settings -> Variables -> add new variable
# Key: GOOGLE_API_KEY, Value: AIzaSyAYvYqwvqia4qkrmTwd7oxxBMXd4Y3sbeE
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ===============================
# BÃ–LÃœM 4: Fonksiyonlar
# ===============================

@st.cache_resource
def load_vector_store():
    """FAISS vector store'u yÃ¼kler veya oluÅŸturur."""
    if os.path.exists(FAISS_INDEX_PATH):
        with open(FAISS_INDEX_PATH, 'rb') as f:
            vectorstore = pickle.load(f)
        return vectorstore
    else:
        with open(DATA_FILE, 'r', encoding='utf-8') as file:
            text = file.read()

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=100,
            separators=["\n### ", "\n\n", "\n", " ", ""]
        )
        chunks = text_splitter.split_text(text)

        embeddings = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )

        vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)

        with open(FAISS_INDEX_PATH, 'wb') as f:
            pickle.dump(vectorstore, f)

        return vectorstore


def get_response(question: str, vectorstore):
    """KullanÄ±cÄ± sorusuna Gemini kullanarak RAG yanÄ±tÄ± Ã¼retir."""
    try:
        llm = ChatGoogleGenerativeAI(
            api_key=GOOGLE_API_KEY,
            model="gemini-2.0-flash",
            temperature=0.3,
            max_output_tokens=512
        )

        retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
        relevant_docs = retriever.invoke(question)
        context = "\n\n".join([doc.page_content for doc in relevant_docs])

        prompt = f"""
Sen Nil YaÄŸmur Muslu'nun kiÅŸisel CV asistanÄ±sÄ±n. Verilen baÄŸlam bilgilerini kullanarak sorularÄ± yanÄ±tla.
BAÄLAM:
{context}

SORU: {question}

YANITLAMA KURALLARI:
1. Sadece verilen baÄŸlam bilgilerini kullan.
2. TÃ¼rkÃ§e olarak yanÄ±tla.
3. Samimi ama profesyonel bir Ã¼slup kullan.
4. EÄŸer bilgi baÄŸlamda yoksa, "Bu konuda bilgim yok" de.
5. KÄ±sa ve net yanÄ±tlar ver.
YANIT:
"""

        response = llm.invoke(prompt)
        return response.content

    except Exception as e:
        return f"âŒ Hata: {e}"


# ===============================
# BÃ–LÃœM 5: Ana Uygulama
# ===============================
def main():
    st.title("ğŸ¤– Nil YaÄŸmur Muslu - CV Chatbot")
    st.markdown("### KiÅŸisel Asistan")
    st.markdown("---")

    st.info("ğŸ’¬ **Merhaba!** Ben Nil YaÄŸmur Muslu'nun CV asistanÄ±yÄ±m. Onun hakkÄ±nda merak ettiklerinizi sorabilirsiniz.")

    try:
        with st.spinner("â³ Vector store yÃ¼kleniyor..."):
            vectorstore = load_vector_store()
        st.success("âœ… Sistem hazÄ±r!")
    except Exception as e:
        st.error(f"âŒ Hata: {e}")
        return

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Sorunuzu buraya yazÄ±n..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                response = get_response(prompt, vectorstore)
            st.markdown(response)

        st.session_state.messages.append({"role": "assistant", "content": response})

    st.markdown("---")
    st.markdown(
        "<div style='text-align: center'><p>ğŸ’» Nil YaÄŸmur Muslu'nun kiÅŸisel CV asistanÄ±</p></div>",
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()

